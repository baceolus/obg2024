# OBG 2024

Exploration of eval approaches for LLMs in bioinformatics:

* `use_tools`: Can LLMs generate code using existing tools or packages to accomplish specified tasks? We grade whether LLMs can generate scripts which, when executed, map inputs (unseen by the LLM) to known-correct outputs.
* `fix_bugs`: Can LLMs fix bugs in existing bioinformatics scripts/snippets? We grade whether LLMs can take a bugged script and produce a script that, when executed, reproduces the outputs of the original unseen correct script.
